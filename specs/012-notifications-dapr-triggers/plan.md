# Implementation Plan: Notifications, Reminders & Dapr Integration

**Branch**: `012-notifications-dapr-triggers` | **Date**: 2025-12-11 | **Spec**: `/specs/012-notifications-dapr-triggers/spec.md`

## Summary

This feature completes the recurring tasks implementation by fixing the critical bug where `recurrence_trigger=on_due_date` silently fails (users can set it but nothing happens), and adds a comprehensive notification system with Dapr event integration. The implementation is split into three prioritized phases:

**P1 (Critical Bug Fix)**: Cron handler to spawn recurring tasks when due_date passes
**P2 (Core Notifications)**: Notification model, reminders, and assignment notifications
**P3 (User Experience)**: Frontend bell, completion/spawn notifications, Dapr event publishing

**Technical Approach**: Direct notification creation (API writes to DB, Dapr events for observability only). Row-level locking with `SELECT FOR UPDATE SKIP LOCKED` prevents cron race conditions. The notification table lives in the same PostgreSQL instance as the main API, avoiding separate service complexity while ensuring the system remains operational even if Dapr is unavailable.

---

## Technical Context

**Language/Version**: Python 3.13+ (backend), TypeScript 5.x (frontend)
**Primary Dependencies**: FastAPI, SQLModel, APScheduler (cron), Dapr SDK (optional), Next.js 16
**Storage**: Neon PostgreSQL (same instance for notifications)
**Testing**: pytest (backend), manual testing (frontend bell)
**Target Platform**: Phase V Production (DOKS with Dapr sidecars)
**Project Type**: Web (backend + frontend)
**Performance Goals**:
- Cron processing: <30s for 1000 tasks
- Notification creation: <100ms per notification
- Reminder delivery: <5 minutes of entering 24h window
- Assignment notifications: <5 seconds after assignment
- Frontend polling: 30-second interval

**Constraints**:
- Cron must complete within 60 seconds (non-overlapping runs)
- Row-level locking required for concurrency safety
- Notification operations must be non-blocking (continue if Dapr unavailable)
- Single database transaction for spawn operations (atomicity)
- No duplicate notifications for same event (idempotency)

**Scale/Scope**:
- Support 1000+ recurring tasks per project
- Handle 10,000+ notifications per user
- 90-day notification retention (configurable)
- Cron runs every 60 seconds (supports 1-minute recurrence patterns)

---

## Constitution Check

✅ **Principle 1: Every Action MUST Be Auditable**
- All cron spawns create audit entries: `task.spawned_recurring` action
- Reminder sends create audit entries: `task.reminder_sent` action
- Assignment, completion, spawn actions logged via existing audit trail

✅ **Principle 2: Agents Are First-Class Citizens**
- Notifications work for both human and agent assignees
- MCP server exposes `list_notifications`, `mark_notification_read` tools
- Agents receive same notification types as humans

✅ **Principle 3: Recursive Task Decomposition**
- Cron respects `clone_subtasks_on_recur=True` when spawning
- Subtask cloning maintains parent-child relationships in new occurrence

✅ **Principle 4: Spec-Driven Development**
- Plan derived from `specs/012-notifications-dapr-triggers/spec.md`
- All acceptance scenarios from spec mapped to implementation phases

✅ **Principle 5: Phase Continuity**
- Notification model designed to work in all phases (P2 web → P5 production)
- Dapr integration optional (works without it in earlier phases)
- Same notification schema used by API, MCP, and future WebSocket handlers

---

## Project Structure

### Documentation (this feature)

```text
specs/012-notifications-dapr-triggers/
├── spec.md              # Feature specification (already exists)
├── plan.md              # This file (/sp.plan command output)
└── tasks.md             # Generated by /sp.tasks command (NOT created by /sp.plan)
```

### Source Code (repository root)

```text
# Backend (FastAPI)
packages/api/src/taskflow_api/
├── models/
│   ├── notification.py          # NEW: Notification SQLModel
│   ├── task.py                  # MODIFIED: reminder_sent field already exists
│   └── __init__.py              # MODIFIED: Import Notification
├── routers/
│   ├── cron.py                  # NEW: Cron handler endpoints (or dapr.py)
│   ├── notifications.py         # NEW: Notification CRUD endpoints
│   ├── tasks.py                 # MODIFIED: Assignment & completion notification hooks
│   └── __init__.py              # MODIFIED: Import new routers
├── services/
│   ├── events.py                # NEW: Dapr event publishing service
│   ├── audit.py                 # EXISTING: Used for cron audit entries
│   └── user_setup.py            # EXISTING: Used in notification creation
├── schemas/
│   └── notification.py          # NEW: Notification Pydantic schemas (Create, Read, Update)
├── config.py                    # MODIFIED: Add DAPR_ENABLED, NOTIFICATION_RETENTION_DAYS
└── main.py                      # MODIFIED: Import and include new routers, start APScheduler

# Frontend (Next.js 16)
web-dashboard/src/
├── components/
│   ├── NotificationBell.tsx     # NEW: Bell icon with dropdown
│   ├── NotificationItem.tsx     # NEW: Individual notification display
│   └── Header.tsx               # MODIFIED: Add NotificationBell component
├── lib/
│   └── api.ts                   # MODIFIED: Add notification API client functions
├── types/
│   └── notification.ts          # NEW: Notification TypeScript types
└── app/
    └── layout.tsx               # MODIFIED: Import Header updates (if needed)

# Tests
packages/api/src/taskflow_api/tests/
├── test_cron.py                 # NEW: Unit tests for cron logic
├── test_notifications.py        # NEW: Integration tests for notification CRUD
└── test_tasks.py                # MODIFIED: Add tests for notification side effects
```

**Structure Decision**: TaskFlow uses a monorepo with `packages/api` (FastAPI backend) and `web-dashboard` (Next.js frontend). This feature adds notification capabilities to both layers while maintaining the existing separation. The `services/events.py` module handles Dapr integration with graceful degradation when Dapr is unavailable.

---

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

No constitutional violations. All five principles upheld:
- Audit coverage complete (cron actions logged)
- Agent parity maintained (MCP tools for notifications)
- Recursive tasks respected (subtask cloning in cron)
- Spec-driven (plan from spec.md)
- Phase continuity (notification model stable across phases)

---

## Phase Breakdown

### Phase 0: Research (Completed)

**Status**: ✅ Complete (spec.md exists)

**Artifacts**:
- Spec captured in `specs/012-notifications-dapr-triggers/spec.md`
- User scenarios defined with P1/P2/P3 priorities
- Critical bug identified: `on_due_date` trigger silently fails
- Technical decision made: Direct notification creation (not event-driven)

**Key Findings**:
- Agent 2A implemented 7 recurring task fields but left `on_due_date` trigger unimplemented
- Row-level locking (`SELECT FOR UPDATE SKIP LOCKED`) prevents duplicate spawns in concurrent cron runs
- 24-hour reminder window meets user needs without over-notification
- Dapr events are observability layer, not critical path (ensures SC-005: operational without event bus)

---

### Phase 1: Design & Architecture

**Goal**: Design database schema, API contracts, and cron logic before implementation.

#### Deliverable 1.1: Notification Data Model

**Entity**: `Notification`

```python
class Notification(SQLModel, table=True):
    """In-app notification for users."""

    __tablename__ = "notification"

    id: int | None = Field(default=None, primary_key=True)
    user_id: str = Field(index=True, description="@human-name or @agent-name")
    user_type: Literal["human", "agent"] = Field(description="Recipient type")

    type: str = Field(
        description="Notification type: task_assigned, task_completed, task_spawned, task_reminder"
    )
    title: str = Field(max_length=200, description="Notification headline")
    body: str = Field(description="Notification message content")

    # Optional links to related entities
    task_id: int | None = Field(default=None, foreign_key="task.id", index=True)
    project_id: int | None = Field(default=None, foreign_key="project.id", index=True)

    read: bool = Field(default=False, description="Whether user has read this notification")
    created_at: datetime = Field(default_factory=datetime.utcnow)

    # Relationships
    task: "Task" = Relationship()
    project: "Project" = Relationship()
```

**Indexes**:
- `user_id` (frequent filter: "get my notifications")
- `task_id` (link notifications to tasks)
- `created_at` (sort by recency)
- Composite index: `(user_id, read, created_at)` (optimizes unread count query)

**Retention Policy**:
- Automatic deletion of notifications older than 90 days
- Configurable via `NOTIFICATION_RETENTION_DAYS` environment variable
- Cleanup runs daily via APScheduler (separate from main cron)

---

#### Deliverable 1.2: Cron Logic Design

**Cron Schedule**: Every 60 seconds (APScheduler)

**Query Pattern** (Prevents Race Conditions):

```python
# Step 1: Find tasks due for spawn (with row-level lock)
stmt = (
    select(Task)
    .where(
        Task.is_recurring == True,
        Task.recurrence_trigger.in_(["on_due_date", "both"]),
        Task.due_date <= datetime.utcnow(),
        Task.has_spawned_next == False,
    )
    .with_for_update(skip_locked=True)  # Critical: Prevent duplicate spawns
)

# Step 2: For each task, spawn next occurrence in transaction
async with session.begin():  # Transaction boundary
    new_task = Task(
        title=original.title,
        description=original.description,
        project_id=original.project_id,
        assignee_id=original.assignee_id,
        recurring_root_id=original.recurring_root_id or original.id,
        due_date=calculate_next_due(original.recurrence_pattern, original.due_date),
        is_recurring=True,
        recurrence_pattern=original.recurrence_pattern,
        max_occurrences=original.max_occurrences,
        recurrence_trigger=original.recurrence_trigger,
        clone_subtasks_on_recur=original.clone_subtasks_on_recur,
        # ... other fields
    )
    session.add(new_task)

    # Mark original as spawned
    original.has_spawned_next = True

    # Clone subtasks if configured
    if original.clone_subtasks_on_recur:
        await clone_subtasks(session, original.id, new_task.id)

    # Create audit entry
    await log_action(
        session,
        task_id=original.id,
        actor_id="@system",
        actor_type="system",
        action="task.spawned_recurring",
        context={"new_task_id": new_task.id}
    )

    # Create notification for assignee
    if new_task.assignee_id:
        assignee = await session.get(Worker, new_task.assignee_id)
        notification = Notification(
            user_id=f"@{assignee.name}",
            user_type=assignee.type,
            type="task_spawned",
            title="Recurring task created",
            body=f'New occurrence of "{new_task.title}" is ready',
            task_id=new_task.id,
            project_id=new_task.project_id,
        )
        session.add(notification)

    await session.commit()  # Atomic spawn
```

**Idempotency Guarantees**:
- `has_spawned_next=True` prevents re-spawn on retry
- `SELECT FOR UPDATE SKIP LOCKED` prevents concurrent spawns
- Transaction ensures all-or-nothing (task + audit + notification)

**Max Occurrences Check**:

```python
# Before spawning, count existing occurrences
if original.max_occurrences:
    root_id = original.recurring_root_id or original.id
    stmt = select(func.count(Task.id)).where(
        (Task.id == root_id) | (Task.recurring_root_id == root_id)
    )
    count = await session.scalar(stmt)

    if count >= original.max_occurrences:
        # Log audit entry: max_occurrences reached
        await log_action(session, task_id=original.id, action="task.recurrence_limit_reached")
        continue  # Skip spawn
```

---

#### Deliverable 1.3: Reminder Logic Design

**Query Pattern** (24-hour Window):

```python
# Find tasks due within 24 hours that haven't sent reminder
now = datetime.utcnow()
reminder_window = now + timedelta(hours=24)

stmt = (
    select(Task)
    .where(
        Task.due_date.between(now, reminder_window),
        Task.reminder_sent == False,
        Task.status.in_(["pending", "in_progress", "blocked"]),  # Not completed
        Task.assignee_id.isnot(None),  # Has assignee
    )
    .with_for_update(skip_locked=True)
)

for task in await session.exec(stmt):
    assignee = await session.get(Worker, task.assignee_id)

    # Calculate hours until due
    hours_until_due = (task.due_date - now).total_seconds() / 3600

    notification = Notification(
        user_id=f"@{assignee.name}",
        user_type=assignee.type,
        type="task_reminder",
        title=f"Task due in {int(hours_until_due)} hours",
        body=f'"{task.title}" is approaching its deadline',
        task_id=task.id,
        project_id=task.project_id,
    )
    session.add(notification)

    # Mark reminder sent
    task.reminder_sent = True

    # Audit log
    await log_action(session, task_id=task.id, action="task.reminder_sent")

    await session.commit()
```

**Edge Case Handling**:
- Completed/cancelled tasks: Excluded by status filter
- Unassigned tasks: Excluded by `assignee_id.isnot(None)`
- Duplicate reminders: Prevented by `reminder_sent=True` flag

---

#### Deliverable 1.4: API Contracts

**Notification Endpoints**:

```python
# GET /api/notifications
# Query params: ?unread_only=true&limit=10&offset=0
# Returns: List[NotificationRead]
# Auth: Current user's notifications only

# GET /api/notifications/unread-count
# Returns: {"count": 5}
# Auth: Current user

# PATCH /api/notifications/{id}/read
# Body: {"read": true}
# Returns: NotificationRead
# Auth: Must own notification

# POST /api/notifications (Internal only - used by cron/assignment hooks)
# Body: NotificationCreate
# Returns: NotificationRead
```

**Cron Endpoints** (Internal/Admin Only):

```python
# POST /api/cron/process-recurring-tasks
# Triggers: On-due-date spawn logic
# Returns: {"spawned": 5, "skipped": 2}
# Auth: System/admin only (API key or internal call)

# POST /api/cron/send-reminders
# Triggers: 24-hour reminder logic
# Returns: {"sent": 12}
# Auth: System/admin only
```

**Modified Task Endpoints**:

```python
# PATCH /api/tasks/{id}/assign (existing endpoint)
# MODIFIED: Add notification creation after assignment
# Notification type: "task_assigned"

# PATCH /api/tasks/{id}/complete (existing endpoint)
# MODIFIED: Add notification to creator if different from completer
# Notification type: "task_completed"
```

---

#### Deliverable 1.5: Dapr Event Schema

**Events Published** (Observability Only):

```python
# Event: task.assigned
{
    "task_id": 123,
    "assignee_id": "@claude-code",
    "assignee_type": "agent",
    "assigned_by": "@muhammad",
    "project_id": 1,
    "timestamp": "2025-12-11T12:00:00Z"
}

# Event: task.completed
{
    "task_id": 123,
    "completed_by": "@sarah",
    "task_creator": "@muhammad",
    "project_id": 1,
    "timestamp": "2025-12-11T12:00:00Z"
}

# Event: task.spawned
{
    "original_task_id": 100,
    "new_task_id": 101,
    "recurrence_pattern": "weekly",
    "trigger_type": "on_due_date",
    "project_id": 1,
    "timestamp": "2025-12-11T12:00:00Z"
}

# Event: task.reminder
{
    "task_id": 123,
    "assignee_id": "@claude-code",
    "hours_until_due": 12,
    "project_id": 1,
    "timestamp": "2025-12-11T12:00:00Z"
}
```

**Publishing Pattern** (Non-Blocking):

```python
async def publish_event(event_type: str, data: dict):
    """Publish event to Dapr pub/sub (non-blocking)."""
    if not settings.DAPR_ENABLED:
        logger.debug(f"Dapr disabled, event logged: {event_type}")
        return

    try:
        async with httpx.AsyncClient() as client:
            await client.post(
                f"{settings.DAPR_HTTP_ENDPOINT}/v1.0/publish/{settings.DAPR_PUBSUB_NAME}/task-events",
                json={"type": event_type, "data": data},
                timeout=1.0  # Fast fail
            )
    except Exception as e:
        logger.warning(f"Dapr event publish failed: {e}")
        # Continue - event publishing is not critical path
```

---

### Phase 2: Implementation Sequence

Implementation follows spec priorities (P1 → P2 → P3) to deliver critical bug fix first.

---

#### P1: Critical Bug Fix - Cron Handler for `on_due_date` Trigger

**Priority**: P1 (Fixes silent failure - highest priority)
**User Story**: "Recurring task spawns on due date" (Acceptance Scenarios 1-4)
**Estimated Effort**: 6-8 hours

**Files Created**:
1. `packages/api/src/taskflow_api/routers/cron.py` (200 lines)
2. `packages/api/src/taskflow_api/tests/test_cron.py` (150 lines)

**Files Modified**:
1. `packages/api/src/taskflow_api/main.py` (add APScheduler initialization)
2. `packages/api/src/taskflow_api/config.py` (add `CRON_ENABLED` flag)
3. `packages/api/src/taskflow_api/routers/__init__.py` (import cron router)

**Implementation Steps**:

1. **Create APScheduler background task** (`main.py`):
   ```python
   from apscheduler.schedulers.asyncio import AsyncIOScheduler
   from contextlib import asynccontextmanager

   scheduler = AsyncIOScheduler()

   @asynccontextmanager
   async def lifespan(app: FastAPI):
       # Startup: Start cron scheduler
       if settings.CRON_ENABLED:
           from .routers.cron import process_recurring_tasks, send_reminders
           scheduler.add_job(process_recurring_tasks, "interval", seconds=60)
           scheduler.add_job(send_reminders, "interval", seconds=60)
           scheduler.start()

       yield

       # Shutdown: Stop scheduler
       if settings.CRON_ENABLED:
           scheduler.shutdown()

   app = FastAPI(lifespan=lifespan)
   ```

2. **Implement cron router** (`routers/cron.py`):
   - Function: `process_recurring_tasks()`
     - Query tasks with `recurrence_trigger IN ('on_due_date', 'both')` and `due_date <= now` and `has_spawned_next=False`
     - Use `SELECT FOR UPDATE SKIP LOCKED` for row-level locking
     - Check `max_occurrences` limit before spawn
     - Calculate next `due_date` using `calculate_next_due()` from `routers/tasks.py`
     - Create new task with cloned fields
     - Clone subtasks if `clone_subtasks_on_recur=True`
     - Mark original `has_spawned_next=True`
     - Create audit entry: `task.spawned_recurring`
     - All in single transaction

   - Function: `clone_subtasks(session, parent_id, new_parent_id)`
     - Recursively clone subtasks
     - Maintain parent-child relationships
     - Preserve assignee, priority, etc.

3. **Add configuration** (`config.py`):
   ```python
   class Settings(BaseSettings):
       CRON_ENABLED: bool = True
       CRON_INTERVAL_SECONDS: int = 60
   ```

4. **Write tests** (`tests/test_cron.py`):
   - Test: `test_spawn_on_due_date_trigger` (Acceptance 1)
   - Test: `test_spawn_with_both_trigger` (Acceptance 2)
   - Test: `test_max_occurrences_limit` (Acceptance 3)
   - Test: `test_idempotency_no_duplicate_spawn` (Acceptance 4)
   - Test: `test_subtask_cloning`
   - Test: `test_audit_entry_created`

**Acceptance Criteria**:
- ✅ Tasks with `recurrence_trigger=on_due_date` spawn when due date passes
- ✅ Tasks with `recurrence_trigger=both` spawn on due date (separate from on_complete)
- ✅ `max_occurrences` limit respected
- ✅ No duplicate spawns (idempotency via `has_spawned_next`)
- ✅ Subtasks cloned if configured
- ✅ Audit trail shows spawn action

**Testing Strategy**:
1. Create recurring task with `due_date` in past, `recurrence_trigger=on_due_date`
2. Run cron handler manually (call `process_recurring_tasks()`)
3. Verify new task created with next due date
4. Verify original task has `has_spawned_next=True`
5. Run cron again → verify no duplicate spawn
6. Test with `max_occurrences=3` → verify spawn stops after limit

---

#### P2: Core Notifications - Model, Reminders, Assignment

**Priority**: P2 (High-frequency productivity features)
**User Stories**: "Task assignment notification" (Acceptance 1-3), "Due date reminder" (Acceptance 1-3)
**Estimated Effort**: 8-10 hours

**Files Created**:
1. `packages/api/src/taskflow_api/models/notification.py` (80 lines)
2. `packages/api/src/taskflow_api/schemas/notification.py` (60 lines)
3. `packages/api/src/taskflow_api/routers/notifications.py` (150 lines)
4. `packages/api/src/taskflow_api/services/events.py` (100 lines)
5. `packages/api/src/taskflow_api/tests/test_notifications.py` (200 lines)

**Files Modified**:
1. `packages/api/src/taskflow_api/models/__init__.py` (import Notification)
2. `packages/api/src/taskflow_api/routers/tasks.py` (add notification hooks in assign/complete)
3. `packages/api/src/taskflow_api/routers/cron.py` (add reminder logic)
4. `packages/api/src/taskflow_api/config.py` (add Dapr settings)
5. `packages/api/src/taskflow_api/main.py` (import notifications router)

**Implementation Steps**:

1. **Create Notification model** (`models/notification.py`):
   - Follow schema from Deliverable 1.1
   - Add relationships to Task, Project
   - Add composite index: `(user_id, read, created_at)`

2. **Create Notification schemas** (`schemas/notification.py`):
   ```python
   class NotificationCreate(SQLModel):
       user_id: str
       user_type: Literal["human", "agent"]
       type: str
       title: str
       body: str
       task_id: int | None = None
       project_id: int | None = None

   class NotificationRead(SQLModel):
       id: int
       user_id: str
       user_type: str
       type: str
       title: str
       body: str
       task_id: int | None
       project_id: int | None
       read: bool
       created_at: datetime

   class NotificationUpdate(SQLModel):
       read: bool
   ```

3. **Create notification router** (`routers/notifications.py`):
   - `GET /api/notifications` (list user's notifications, paginated)
   - `GET /api/notifications/unread-count` (count unread)
   - `PATCH /api/notifications/{id}/read` (mark as read)
   - All endpoints filter by `current_user`

4. **Create event service** (`services/events.py`):
   - Function: `publish_event(event_type: str, data: dict)`
   - Uses `httpx.AsyncClient` to POST to Dapr sidecar
   - Non-blocking: catches exceptions, logs warnings, continues
   - Checks `settings.DAPR_ENABLED` flag before attempting publish

5. **Add notification hooks to tasks router** (`routers/tasks.py`):
   - In `assign_task()` endpoint:
     ```python
     # After assignment
     if new_assignee_id:
         assignee = await session.get(Worker, new_assignee_id)
         notification = Notification(
             user_id=f"@{assignee.name}",
             user_type=assignee.type,
             type="task_assigned",
             title="Task assigned to you",
             body=f'You have been assigned: "{task.title}"',
             task_id=task.id,
             project_id=task.project_id,
         )
         session.add(notification)

         # Publish event (non-blocking)
         await publish_event("task.assigned", {
             "task_id": task.id,
             "assignee_id": f"@{assignee.name}",
             "assigned_by": f"@{current_user.name}",
         })
     ```

   - In `complete_task()` endpoint:
     ```python
     # After completion, notify creator if different
     if task.created_by_id != current_user.id:
         creator = await session.get(Worker, task.created_by_id)
         notification = Notification(
             user_id=f"@{creator.name}",
             user_type=creator.type,
             type="task_completed",
             title="Task completed",
             body=f'{current_user.name} completed: "{task.title}"',
             task_id=task.id,
             project_id=task.project_id,
         )
         session.add(notification)

         await publish_event("task.completed", {...})
     ```

6. **Add reminder logic to cron** (`routers/cron.py`):
   - Function: `send_reminders()`
   - Query tasks due within 24 hours, `reminder_sent=False`, not completed
   - Create `task_reminder` notification for assignee
   - Mark `task.reminder_sent=True`
   - Publish `task.reminder` event

7. **Add Dapr configuration** (`config.py`):
   ```python
   class Settings(BaseSettings):
       DAPR_ENABLED: bool = False  # Default off for dev
       DAPR_HTTP_ENDPOINT: str = "http://localhost:3500"
       DAPR_PUBSUB_NAME: str = "taskflow-pubsub"
       NOTIFICATION_RETENTION_DAYS: int = 90
   ```

8. **Write tests** (`tests/test_notifications.py`):
   - Test: `test_list_notifications` (filtered by user)
   - Test: `test_unread_count`
   - Test: `test_mark_as_read`
   - Test: `test_assignment_creates_notification` (Acceptance 1)
   - Test: `test_notification_bell_unread_badge` (Acceptance 2)
   - Test: `test_click_notification_marks_read` (Acceptance 3)
   - Test: `test_reminder_sent_within_24h` (Acceptance 1)
   - Test: `test_no_duplicate_reminder` (Acceptance 2)
   - Test: `test_completed_task_no_reminder` (Acceptance 3)

**Acceptance Criteria**:
- ✅ Task assignment creates notification within 5 seconds (Spec SC-003)
- ✅ Unread count badge shows on frontend bell
- ✅ Clicking notification marks it as read
- ✅ Reminders sent within 5 minutes of entering 24h window (Spec SC-002)
- ✅ No duplicate reminders (idempotency via `reminder_sent`)
- ✅ Completed tasks excluded from reminders

**Testing Strategy**:
1. Assign task to user → verify notification appears in their list
2. Check unread count before/after reading
3. Create task due in 23 hours → run cron → verify reminder sent
4. Create task due in 25 hours → run cron → verify no reminder yet
5. Complete task with reminder due → verify no reminder sent

---

#### P3: User Experience - Frontend Bell & Completion/Spawn Notifications

**Priority**: P3 (Delivery mechanism for notifications)
**User Stories**: "Notification bell in UI" (Acceptance 1-4), "Task completion notification", "Recurring task spawn notification"
**Estimated Effort**: 6-8 hours

**Files Created**:
1. `web-dashboard/src/components/NotificationBell.tsx` (200 lines)
2. `web-dashboard/src/components/NotificationItem.tsx` (80 lines)
3. `web-dashboard/src/types/notification.ts` (40 lines)

**Files Modified**:
1. `web-dashboard/src/components/Header.tsx` (add NotificationBell)
2. `web-dashboard/src/lib/api.ts` (add notification API functions)
3. `packages/api/src/taskflow_api/routers/cron.py` (add spawn notification)

**Implementation Steps**:

1. **Create notification TypeScript types** (`types/notification.ts`):
   ```typescript
   export type NotificationType =
     | "task_assigned"
     | "task_completed"
     | "task_spawned"
     | "task_reminder";

   export interface Notification {
     id: number;
     user_id: string;
     user_type: "human" | "agent";
     type: NotificationType;
     title: string;
     body: string;
     task_id?: number;
     project_id?: number;
     read: boolean;
     created_at: string;
   }
   ```

2. **Add notification API functions** (`lib/api.ts`):
   ```typescript
   export async function getNotifications(unreadOnly = false, limit = 10) {
     const params = new URLSearchParams({
       unread_only: unreadOnly.toString(),
       limit: limit.toString()
     });
     const response = await fetch(`/api/notifications?${params}`);
     return response.json();
   }

   export async function getUnreadCount() {
     const response = await fetch("/api/notifications/unread-count");
     const data = await response.json();
     return data.count;
   }

   export async function markNotificationRead(id: number) {
     await fetch(`/api/notifications/${id}/read`, {
       method: "PATCH",
       headers: { "Content-Type": "application/json" },
       body: JSON.stringify({ read: true }),
     });
   }
   ```

3. **Create NotificationItem component** (`components/NotificationItem.tsx`):
   - Display notification icon based on type
   - Show title, body, timestamp (relative: "2 hours ago")
   - Link to task/project if IDs present
   - Visual indicator for unread (bold text or dot)
   - Click handler: mark as read, navigate to task

4. **Create NotificationBell component** (`components/NotificationBell.tsx`):
   - Bell icon with badge (unread count)
   - Polling: `useEffect` with 30-second interval to fetch unread count
   - Dropdown: Show 10 most recent notifications
   - Badge display: "3" for 1-9, "9+" for 10+
   - Click bell → toggle dropdown
   - Click outside → close dropdown
   - Empty state: "No notifications"

5. **Add NotificationBell to Header** (`components/Header.tsx`):
   ```tsx
   import { NotificationBell } from "./NotificationBell";

   export function Header() {
     return (
       <header>
         {/* Existing header content */}
         <NotificationBell />
       </header>
     );
   }
   ```

6. **Add spawn notification to cron** (`routers/cron.py`):
   - In `process_recurring_tasks()`, after spawning new task:
     ```python
     # Create notification for assignee (P3 - spawn notification)
     if new_task.assignee_id:
         assignee = await session.get(Worker, new_task.assignee_id)
         notification = Notification(
             user_id=f"@{assignee.name}",
             user_type=assignee.type,
             type="task_spawned",
             title="Recurring task created",
             body=f'New occurrence of "{new_task.title}" is ready',
             task_id=new_task.id,
             project_id=new_task.project_id,
         )
         session.add(notification)

         await publish_event("task.spawned", {...})
     ```

**Acceptance Criteria**:
- ✅ Bell icon displays unread count badge (Acceptance 1)
- ✅ Badge shows "9+" for 10+ notifications (Acceptance 2)
- ✅ Dropdown shows 10 most recent notifications with type icons (Acceptance 3)
- ✅ Clicking "View" navigates to task detail page (Acceptance 4)
- ✅ Spawn notifications created when recurring task auto-spawns (Acceptance 1-2)
- ✅ Completion notifications sent to task creator (Acceptance 1)
- ✅ No self-notifications (Acceptance 2)

**Testing Strategy**:
1. Create 3 unread notifications → verify badge shows "3"
2. Create 12 unread → verify badge shows "9+"
3. Click bell → verify dropdown opens with 10 items
4. Click notification with task_id → verify navigation to task detail
5. Complete recurring task → verify assignee gets spawn notification
6. Complete own task → verify no completion notification sent

---

### Phase 3: MCP Integration (Agent Parity)

**Goal**: Expose notification operations to agents via MCP server.

**Estimated Effort**: 2-3 hours

**Files Modified**:
1. `packages/mcp-server/src/taskflow_mcp/server.py` (add notification tools)

**New MCP Tools**:

```python
@mcp_server.tool()
async def list_notifications(
    unread_only: bool = False,
    limit: int = 10
) -> list[dict]:
    """List notifications for the authenticated agent.

    Args:
        unread_only: Only return unread notifications
        limit: Maximum number of notifications to return

    Returns:
        List of notification objects
    """
    # Call /api/notifications with agent's API key
    # Return notification list

@mcp_server.tool()
async def mark_notification_read(notification_id: int) -> dict:
    """Mark a notification as read.

    Args:
        notification_id: ID of notification to mark as read

    Returns:
        Updated notification object
    """
    # Call PATCH /api/notifications/{id}/read
    # Return updated notification
```

**Acceptance Criteria**:
- ✅ Agents can list their notifications via MCP
- ✅ Agents can mark notifications as read
- ✅ Agents receive same notification types as humans (assignment, reminder, spawn)

**Testing Strategy**:
1. Assign task to agent via MCP → verify agent can list notification
2. Agent marks notification read → verify read status persists
3. Create recurring task assigned to agent → verify spawn notification appears in agent's list

---

### Phase 4: Testing & Validation

**Goal**: Ensure all acceptance scenarios pass and system meets success criteria.

**Test Coverage Matrix**:

| Test Type | Coverage Target | Files |
|-----------|----------------|-------|
| Unit Tests | Cron logic, notification CRUD | `test_cron.py`, `test_notifications.py` |
| Integration Tests | API endpoints, database transactions | `test_tasks.py` (modified) |
| Manual Tests | Frontend bell, real-time polling | Manual QA checklist |
| Concurrency Tests | Row-level locking, no duplicate spawns | `test_cron.py` |

**Key Test Scenarios**:

1. **Concurrent Cron Runs** (Validates Row-Level Locking):
   - Start two cron jobs simultaneously
   - Verify only one spawns new task
   - Verify no duplicate audit entries

2. **Notification Delivery SLA** (Validates SC-003):
   - Assign task → measure time to notification creation
   - Assert < 5 seconds

3. **Reminder Window Accuracy** (Validates SC-002):
   - Create tasks at 23h, 24h, 25h until due
   - Run cron → verify only 23h gets reminder
   - Wait 1 hour → verify 24h gets reminder

4. **Frontend Polling** (Validates SC-004):
   - Create notification → wait 30 seconds
   - Verify unread count updates in UI

5. **Dapr Degradation** (Validates SC-005):
   - Disable Dapr (`DAPR_ENABLED=False`)
   - Assign task → verify notification still created
   - Verify API continues functioning

**Success Metrics** (From Spec):
- ✅ SC-001: `on_due_date` triggers spawn 100% of time
- ✅ SC-002: Reminders within 5 minutes of 24h window
- ✅ SC-003: Assignment notifications within 5 seconds
- ✅ SC-004: Bell updates within 30 seconds
- ✅ SC-005: System operational without Dapr
- ✅ SC-006: Notification CRUD < 1 second
- ✅ SC-007: No duplicate notifications (idempotency)

---

## Implementation Checklist

### P1: Critical Bug Fix (6-8 hours)
- [ ] Create `routers/cron.py` with `process_recurring_tasks()` function
- [ ] Implement row-level locking (`SELECT FOR UPDATE SKIP LOCKED`)
- [ ] Add `max_occurrences` check before spawn
- [ ] Implement subtask cloning logic
- [ ] Add APScheduler to `main.py` lifespan
- [ ] Add `CRON_ENABLED` config flag
- [ ] Write unit tests for spawn logic (4 acceptance scenarios)
- [ ] Test with `recurrence_trigger=on_due_date` and `both`
- [ ] Verify audit entries created for spawns
- [ ] Verify idempotency (no duplicate spawns on retry)

### P2: Core Notifications (8-10 hours)
- [ ] Create `models/notification.py` with Notification SQLModel
- [ ] Create `schemas/notification.py` (Create, Read, Update)
- [ ] Create `routers/notifications.py` (list, unread count, mark read)
- [ ] Create `services/events.py` (Dapr event publishing)
- [ ] Add notification hooks to `routers/tasks.py` (assign, complete)
- [ ] Add reminder logic to `routers/cron.py` (`send_reminders()`)
- [ ] Add Dapr config to `config.py`
- [ ] Write integration tests for notification CRUD
- [ ] Test assignment notification (within 5 seconds)
- [ ] Test reminder notification (24-hour window)
- [ ] Test completion notification (creator != completer)
- [ ] Verify Dapr events publish (or log if disabled)

### P3: Frontend Bell (6-8 hours)
- [ ] Create `types/notification.ts` (Notification interface)
- [ ] Add notification API functions to `lib/api.ts`
- [ ] Create `components/NotificationItem.tsx`
- [ ] Create `components/NotificationBell.tsx` (bell + dropdown)
- [ ] Add 30-second polling in NotificationBell
- [ ] Implement unread badge (count, "9+" for 10+)
- [ ] Add NotificationBell to Header
- [ ] Add spawn notification to cron handler
- [ ] Test bell displays unread count
- [ ] Test dropdown shows 10 recent notifications
- [ ] Test clicking notification marks as read
- [ ] Test navigation to task from notification

### MCP Integration (2-3 hours)
- [ ] Add `list_notifications` MCP tool
- [ ] Add `mark_notification_read` MCP tool
- [ ] Test agents can list their notifications
- [ ] Test agents receive assignment/spawn notifications

### Testing & Validation (4-6 hours)
- [ ] Run full test suite (`uv run pytest`)
- [ ] Manual test: concurrent cron runs (row-level locking)
- [ ] Manual test: notification delivery SLA (<5s)
- [ ] Manual test: reminder window accuracy (24h)
- [ ] Manual test: frontend polling (30s interval)
- [ ] Manual test: Dapr degradation (API works without Dapr)
- [ ] Verify all 7 success criteria (SC-001 to SC-007)
- [ ] Verify all acceptance scenarios pass (18 scenarios across 6 user stories)

---

## Deployment Considerations

### Environment Variables (Production)

```bash
# Cron Configuration
CRON_ENABLED=true
CRON_INTERVAL_SECONDS=60

# Dapr Configuration
DAPR_ENABLED=true
DAPR_HTTP_ENDPOINT=http://localhost:3500
DAPR_PUBSUB_NAME=taskflow-pubsub

# Notification Configuration
NOTIFICATION_RETENTION_DAYS=90
```

### Dapr Component Configuration (Phase V - DOKS)

**`components/pubsub.yaml`**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: taskflow-pubsub
spec:
  type: pubsub.kafka
  version: v1
  metadata:
    - name: brokers
      value: "redpanda-0.redpanda.svc.cluster.local:9092"
    - name: consumerGroup
      value: "taskflow-notifications"
    - name: authType
      value: "none"
```

**Pub/Sub Topic**: `task-events`

**Subscribers** (Future Enhancement):
- Analytics service (consumes all events for metrics)
- Webhook service (consumes events for external integrations)

### Database Migration

**Migration**: `add_notification_table_and_reminder_field.sql`

```sql
-- Create notification table
CREATE TABLE notification (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(100) NOT NULL,
    user_type VARCHAR(10) NOT NULL CHECK (user_type IN ('human', 'agent')),
    type VARCHAR(50) NOT NULL,
    title VARCHAR(200) NOT NULL,
    body TEXT NOT NULL,
    task_id INTEGER REFERENCES task(id) ON DELETE CASCADE,
    project_id INTEGER REFERENCES project(id) ON DELETE CASCADE,
    read BOOLEAN NOT NULL DEFAULT FALSE,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_notification_user_id ON notification(user_id);
CREATE INDEX idx_notification_task_id ON notification(task_id);
CREATE INDEX idx_notification_created_at ON notification(created_at);
CREATE INDEX idx_notification_user_read_created ON notification(user_id, read, created_at);

-- reminder_sent field already added to task table in previous migration
-- (Agent 2A added this field, so no migration needed here)
```

**Rollback Plan**:
```sql
DROP TABLE notification CASCADE;
-- Note: Do NOT drop reminder_sent from task - it was added by Agent 2A
```

### Monitoring & Observability

**Key Metrics to Track**:
- Cron execution time (alert if >50s)
- Cron spawn rate (tasks spawned per run)
- Notification creation rate (per type)
- Dapr event publish success rate
- Notification delivery SLA (time from event to notification creation)
- Unread notification count per user (detect notification fatigue)

**Alerts**:
- Cron execution failure (>3 consecutive failures)
- Notification creation delay (>10s from event)
- Dapr publish failure rate (>10% over 5 minutes)
- Database lock contention (cron row locks timing out)

---

## Risk Analysis & Mitigation

| Risk | Impact | Likelihood | Mitigation |
|------|--------|-----------|------------|
| **Cron overlapping runs** | Duplicate spawns, data corruption | Medium | Use row-level locking (`SKIP LOCKED`), add execution time monitoring, alert if >50s |
| **Notification spam** | User fatigue, ignored notifications | Medium | 90-day retention, future: user preferences for notification types |
| **Dapr unavailability** | Lost observability events | Low | Events are non-blocking, system continues, events logged locally |
| **Database lock contention** | Cron slowdown, timeouts | Low | `SKIP LOCKED` allows concurrent processing, monitor lock wait times |
| **Polling overhead** | Frontend performance | Low | 30s interval is conservative, future: WebSocket for real-time updates |
| **Timezone confusion** | Wrong reminder times | Medium | All times in UTC, frontend displays in user's local timezone (separate concern) |

---

## Future Enhancements (Out of Scope for MVP)

**Post-MVP Features** (Not in current spec):
1. Real-time WebSocket notifications (replace polling)
2. Email/SMS notifications (multi-channel delivery)
3. User notification preferences (mute types, frequency)
4. Notification grouping/batching (reduce spam)
5. Custom reminder times per task (not just 24h)
6. Notification read receipts in audit trail
7. Digest emails (daily/weekly summary)
8. Mobile push notifications
9. Notification templates (i18n support)
10. Advanced filtering (by project, priority, date range)

**Technical Debt to Address**:
- Notification retention cleanup (add scheduled job)
- Cron execution metrics (add Prometheus integration)
- Dapr circuit breaker (retry logic for transient failures)
- Frontend notification cache (reduce API calls)
- WebSocket infrastructure (Phase VI)

---

## References

**Spec**: `/specs/012-notifications-dapr-triggers/spec.md`
**Constitution**: `.specify/memory/constitution.md`
**Directives**: `research/DIRECTIVES.md`
**Existing Cron Logic**: `packages/api/src/taskflow_api/routers/tasks.py` (line 100: `calculate_next_due()`)
**Audit Service**: `packages/api/src/taskflow_api/services/audit.py`
**Recurring Task Fields**: `packages/api/src/taskflow_api/models/task.py` (lines 64-97)

---

## Acceptance Sign-Off

This plan will be considered complete when:
- ✅ All P1 acceptance scenarios pass (User Story 1: 4 scenarios)
- ✅ All P2 acceptance scenarios pass (User Stories 2-3: 6 scenarios)
- ✅ All P3 acceptance scenarios pass (User Stories 4-6: 8 scenarios)
- ✅ All 7 success criteria validated (SC-001 to SC-007)
- ✅ Test coverage >80% for new code
- ✅ No duplicate spawns in concurrency test
- ✅ System operational with `DAPR_ENABLED=False`
- ✅ Frontend bell updates within 30 seconds
- ✅ Documentation updated (API docs, deployment guide)

**Estimated Total Effort**: 26-35 hours
**Target Completion**: Phase V Production (DOKS deployment)
**Constitutional Compliance**: ✅ All 5 principles upheld
